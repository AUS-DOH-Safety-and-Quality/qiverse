% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/powerbi_dataflow.R
\name{mount_dataflow_table}
\alias{mount_dataflow_table}
\title{Mount a PowerBI Dataflow Table as a Databricks External Table}
\usage{
mount_dataflow_table(
  workspace_name,
  dataflow_name,
  table_name,
  access_token,
  db_schema,
  db_table,
  print_sql = FALSE
)
}
\arguments{
\item{workspace_name}{The PowerBI workspace name.}

\item{dataflow_name}{The name of the PowerBI Dataflow within the workspace.}

\item{table_name}{The name of the table within the PowerBI Dataflow to be
accessed.}

\item{access_token}{The token generated with the correct PowerBI Dataflow
permissions. Use get_az_tk('pbi_df') to create this token.}

\item{db_schema}{The name of the schema to declare the external table in. Will be created if it does not exist.}

\item{db_table}{The desired name for the new external table}

\item{print_sql}{If TRUE, the function will not actually mount the table, but
will instead print the SQL command that would be executed. Default is FALSE.}
}
\value{
If \code{print_sql} = FALSE, then no return value, called for its side-effects (mounting the external table).
If \code{print_sql} = TRUE, then a character vector of the SQL commands that would be executed
}
\description{
Treat a PBI dataflow table as an external SQL table for use in standard SQL
queries
}
\examples{
 \dontrun{
# Create PowerBI Dataflow azure token
tk <- get_az_tk('pbi_df')

# Create new external table
mount_dataflow_table(
  workspace_name = "My Workspace Name",
  dataflow_name = "My Dataflow Name",
  table_name = "My Table Name",
  access_token = tk$credentials$access_token,
  db_schema = "PBI",
  db_table = "NEW_TABLE"
)
}
}
